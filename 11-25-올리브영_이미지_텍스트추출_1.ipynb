{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b185a2-0afc-45b4-ba2c-74db5ee9da60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# ì˜¬ë¦¬ë¸Œì˜ Top100 ì „ì²´ ì œí’ˆ OCR (txt + xlsx)\n",
    "# ============================================\n",
    "import os\n",
    "import glob\n",
    "from paddleocr import PaddleOCR\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "# ============================================\n",
    "# 1. ê²½ë¡œ ì„¤ì •\n",
    "# ============================================\n",
    "IMG_BASE_DIR = r\"C:\\py_temp\\ì˜¬ë¦¬ë¸Œì˜_ì´ë¯¸ì§€2025-11-25-18-11-12-ì˜¬ë¦¬ë¸Œì˜-ì´ë¯¸ì§€\"\n",
    "OUTPUT_DIR = r\"C:\\Users\\itwill\\Desktop\\ì˜¬ë¦¬ë¸Œì˜\\ì¤‘ê°„í”„ë¡œì íŠ¸ ì½”ìŠ¤ë©”í‹±\"\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# ============================================\n",
    "# 2. PaddleOCR ëª¨ë¸ ë¡œë”©\n",
    "# ============================================\n",
    "print(\"ğŸ”§ PaddleOCR ëª¨ë¸ ë¡œë”© ì¤‘...\")\n",
    "ocr = PaddleOCR(\n",
    "    use_angle_cls=True,\n",
    "    lang='korean'\n",
    ")\n",
    "print(\"âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ!\\n\")\n",
    "\n",
    "# ============================================\n",
    "# 3. ê°•í™”ëœ í…ìŠ¤íŠ¸ ì •ì œ í•¨ìˆ˜\n",
    "# ============================================\n",
    "def clean_text(text):\n",
    "    \"\"\"OCR ê²°ê³¼ ì •ì œ\"\"\"\n",
    "    text = re.sub(r'\\d+\\.?\\d*\\s?(ml|oz|g|mg|kg|l|fl|f1)', '', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'\\b\\d+\\.?\\d*\\b', '', text)\n",
    "    text = re.sub(r'\\d+\\.?\\d*/\\d+\\.?\\d*', '', text)\n",
    "    text = re.sub(r'[^\\w\\sê°€-í£a-zA-Z]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    words = text.split()\n",
    "    filtered_words = []\n",
    "    \n",
    "    for word in words:\n",
    "        if len(word) == 1 and re.match(r'[ê°€-í£ã„±-ã…ã…-ã…£]', word):\n",
    "            continue\n",
    "        if len(word) == 1 and re.match(r'[a-zA-Z]', word):\n",
    "            continue\n",
    "        if word.isdigit():\n",
    "            continue\n",
    "        if len(word) >= 2:\n",
    "            filtered_words.append(word)\n",
    "    \n",
    "    return ' '.join(filtered_words).strip()\n",
    "\n",
    "# ============================================\n",
    "# 4. ëª¨ë“  ì œí’ˆ í´ë” ì°¾ê¸°\n",
    "# ============================================\n",
    "product_folders = sorted([\n",
    "    d for d in os.listdir(IMG_BASE_DIR) \n",
    "    if os.path.isdir(os.path.join(IMG_BASE_DIR, d))\n",
    "])\n",
    "\n",
    "print(f\"ğŸ“ ë°œê²¬ëœ ì œí’ˆ í´ë”: {len(product_folders)}ê°œ\")\n",
    "print(f\"   ì˜ˆì‹œ: {product_folders[:5]}\\n\")\n",
    "\n",
    "if len(product_folders) == 0:\n",
    "    print(\"âš ï¸ ì œí’ˆ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤!\")\n",
    "    exit()\n",
    "\n",
    "# ============================================\n",
    "# 5. ì „ì²´ í†µí•© ê²°ê³¼ ì €ì¥ìš©\n",
    "# ============================================\n",
    "all_products_summary = []\n",
    "total_images_processed = 0\n",
    "total_words_extracted = 0\n",
    "\n",
    "# ============================================\n",
    "# 6. ê° í´ë”ë³„ë¡œ OCR ìˆ˜í–‰\n",
    "# ============================================\n",
    "print(\"=\" * 80)\n",
    "print(\"ğŸš€ ì „ì²´ ì œí’ˆ OCR ì‹œì‘!\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for folder_idx, folder_name in enumerate(product_folders, start=1):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"ğŸ“¦ [{folder_idx}/{len(product_folders)}] {folder_name} í´ë” ì²˜ë¦¬ ì¤‘...\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    IMG_DIR = os.path.join(IMG_BASE_DIR, folder_name)\n",
    "    \n",
    "    img_exts = ['*.png', '*.jpg', '*.jpeg', '*.webp']\n",
    "    img_files = []\n",
    "    \n",
    "    for ext in img_exts:\n",
    "        img_files.extend(glob.glob(os.path.join(IMG_DIR, ext)))\n",
    "    \n",
    "    img_files = sorted(img_files)\n",
    "    \n",
    "    print(f\"   ğŸ“· ì´ë¯¸ì§€ ê°œìˆ˜: {len(img_files)}ì¥\")\n",
    "    \n",
    "    if len(img_files) == 0:\n",
    "        print(f\"   âš ï¸ ì´ë¯¸ì§€ ì—†ìŒ, ë‹¤ìŒ í´ë”ë¡œ ì´ë™\\n\")\n",
    "        continue\n",
    "    \n",
    "    image_results = []\n",
    "    product_text_lines = []\n",
    "    \n",
    "    for img_idx, img_path in enumerate(img_files, start=1):\n",
    "        img_name = os.path.basename(img_path)\n",
    "        \n",
    "        try:\n",
    "            result = ocr.ocr(img_path)\n",
    "            \n",
    "            raw_lines = []\n",
    "            clean_lines = []\n",
    "            \n",
    "            if result and len(result) > 0:\n",
    "                ocr_result = result[0]\n",
    "                \n",
    "                if hasattr(ocr_result, 'rec_texts') and hasattr(ocr_result, 'rec_scores'):\n",
    "                    texts = ocr_result.rec_texts\n",
    "                    scores = ocr_result.rec_scores\n",
    "                    \n",
    "                    for text, score in zip(texts, scores):\n",
    "                        if score >= 0.4:\n",
    "                            raw_lines.append(f\"{text} (ì‹ ë¢°ë„: {score:.2f})\")\n",
    "                            cleaned = clean_text(text)\n",
    "                            if cleaned:\n",
    "                                clean_lines.append(cleaned)\n",
    "                \n",
    "                elif isinstance(ocr_result, dict):\n",
    "                    if 'rec_texts' in ocr_result and 'rec_scores' in ocr_result:\n",
    "                        texts = ocr_result['rec_texts']\n",
    "                        scores = ocr_result['rec_scores']\n",
    "                        \n",
    "                        for text, score in zip(texts, scores):\n",
    "                            if score >= 0.4:\n",
    "                                raw_lines.append(f\"{text} (ì‹ ë¢°ë„: {score:.2f})\")\n",
    "                                cleaned = clean_text(text)\n",
    "                                if cleaned:\n",
    "                                    clean_lines.append(cleaned)\n",
    "            \n",
    "            image_results.append({\n",
    "                \"ì´ë¯¸ì§€\": img_name,\n",
    "                \"ì›ë³¸í…ìŠ¤íŠ¸\": \" \".join([line.split(\" (ì‹ ë¢°ë„:\")[0] for line in raw_lines]),\n",
    "                \"ì •ì œí…ìŠ¤íŠ¸\": \" \".join(clean_lines),\n",
    "                \"ì¤„ìˆ˜\": len(clean_lines)\n",
    "            })\n",
    "            \n",
    "            product_text_lines.extend(clean_lines)\n",
    "            total_images_processed += 1\n",
    "            \n",
    "            if img_idx % 5 == 0 or img_idx == len(img_files):\n",
    "                print(f\"      ì§„í–‰: {img_idx}/{len(img_files)} ì´ë¯¸ì§€ ì™„ë£Œ\", end='\\r')\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"      âš ï¸ {img_name} ì²˜ë¦¬ ì‹¤íŒ¨: {e}\")\n",
    "            image_results.append({\n",
    "                \"ì´ë¯¸ì§€\": img_name,\n",
    "                \"ì›ë³¸í…ìŠ¤íŠ¸\": f\"[ì˜¤ë¥˜: {e}]\",\n",
    "                \"ì •ì œí…ìŠ¤íŠ¸\": \"\",\n",
    "                \"ì¤„ìˆ˜\": 0\n",
    "            })\n",
    "            continue\n",
    "    \n",
    "    df_product = pd.DataFrame(image_results)\n",
    "    excel_path = os.path.join(OUTPUT_DIR, f\"{folder_name}_ocr.xlsx\")\n",
    "    df_product.to_excel(excel_path, index=False)\n",
    "    \n",
    "    product_combined_text = \" \".join(product_text_lines)\n",
    "    txt_path = os.path.join(OUTPUT_DIR, f\"{folder_name}_ocr.txt\")\n",
    "    with open(txt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(product_combined_text)\n",
    "    \n",
    "    all_products_summary.append({\n",
    "        \"ì œí’ˆë²ˆí˜¸\": folder_name,\n",
    "        \"ì´ë¯¸ì§€ìˆ˜\": len(img_files),\n",
    "        \"ì¶”ì¶œë‹¨ì–´ìˆ˜\": len(product_text_lines),\n",
    "        \"í…ìŠ¤íŠ¸\": product_combined_text\n",
    "    })\n",
    "    \n",
    "    total_words_extracted += len(product_text_lines)\n",
    "    \n",
    "    print(f\"\\n   âœ… {folder_name} ì™„ë£Œ: {len(img_files)}ì¥ â†’ {len(product_text_lines)}ë‹¨ì–´ ì¶”ì¶œ\")\n",
    "    print(f\"   ğŸ’¾ ì €ì¥: {folder_name}_ocr.txt, {folder_name}_ocr.xlsx\")\n",
    "    \n",
    "    if folder_idx % 10 == 0:\n",
    "        temp_df = pd.DataFrame(all_products_summary)\n",
    "        temp_df.to_excel(os.path.join(OUTPUT_DIR, \"í†µí•©ê²°ê³¼_ì¤‘ê°„ì €ì¥.xlsx\"), index=False)\n",
    "        print(f\"\\n   ğŸ’¾ ì¤‘ê°„ ì €ì¥ ì™„ë£Œ ({folder_idx}ê°œ ì²˜ë¦¬ë¨)\\n\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ğŸ“Š ì „ì²´ í†µí•© íŒŒì¼ ìƒì„± ì¤‘...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "df_summary = pd.DataFrame(all_products_summary)\n",
    "summary_excel_path = os.path.join(OUTPUT_DIR, \"ì „ì²´ì œí’ˆ_í†µí•©ìš”ì•½.xlsx\")\n",
    "df_summary.to_excel(summary_excel_path, index=False)\n",
    "print(f\"âœ… í†µí•© ìš”ì•½ ì—‘ì…€: {summary_excel_path}\")\n",
    "\n",
    "all_text = \" \".join([item[\"í…ìŠ¤íŠ¸\"] for item in all_products_summary])\n",
    "all_txt_path = os.path.join(OUTPUT_DIR, \"ì „ì²´ì œí’ˆ_í†µí•©í…ìŠ¤íŠ¸.txt\")\n",
    "with open(all_txt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(all_text)\n",
    "print(f\"âœ… í†µí•© txt: {all_txt_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ğŸ‰ ì „ì²´ OCR ì‘ì—… ì™„ë£Œ!\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"ğŸ“Š ì²˜ë¦¬ ê²°ê³¼:\")\n",
    "print(f\"   - ì²˜ë¦¬ëœ ì œí’ˆ: {len(product_folders)}ê°œ\")\n",
    "print(f\"   - ì²˜ë¦¬ëœ ì´ë¯¸ì§€: {total_images_processed}ì¥\")\n",
    "print(f\"   - ì¶”ì¶œëœ ë‹¨ì–´: {total_words_extracted:,}ê°œ\")\n",
    "print(f\"   - ì´ í…ìŠ¤íŠ¸ëŸ‰: {len(all_text):,}ì\")\n",
    "print(f\"\\nğŸ“ ê²°ê³¼ ìœ„ì¹˜: {OUTPUT_DIR}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nğŸ“ˆ ì œí’ˆë³„ í†µê³„ (ìƒìœ„ 10ê°œ):\")\n",
    "df_sorted = df_summary.sort_values('ì¶”ì¶œë‹¨ì–´ìˆ˜', ascending=False)\n",
    "print(df_sorted[['ì œí’ˆë²ˆí˜¸', 'ì´ë¯¸ì§€ìˆ˜', 'ì¶”ì¶œë‹¨ì–´ìˆ˜']].head(10).to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
